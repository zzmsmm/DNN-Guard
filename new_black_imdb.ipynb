{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "w2: [9, 1, 4, 7, 1, 4, 0, 6, 7, 5, 8, 3, 6, 5, 5, 4, 8, 9, 4, 6, 0, 7, 6, 9, 8, 2, 3, 6, 0, 4, 1, 1, 0, 7, 1, 2, 3, 8, 0, 4, 5, 8, 8, 8, 2, 4, 3, 8, 9, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext import data\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import copy\n",
    "import itertools\n",
    "device=torch.device('cuda:2')\n",
    "N=200\n",
    "random.seed(7)\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "\n",
    "class WMDataset(Dataset):\n",
    "    def __init__(self,N):\n",
    "        self.N=N\n",
    "        sentences=[]\n",
    "        for i in range(2*N):\n",
    "            sentence=[]\n",
    "            for j in range(500):\n",
    "                w=int(random.uniform(0,10000))\n",
    "                sentence.append(w)\n",
    "            sentences.append(torch.tensor(sentence))\n",
    "        self.sentences=sentences\n",
    "    def __getitem__(self,index):\n",
    "        label=int(index%2)\n",
    "        s=self.sentences[index]\n",
    "        return s,label\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "w1=[]\n",
    "for j in range(50):\n",
    "    w=int(random.uniform(0,2))\n",
    "    w1.append(w)\n",
    "for j in range(450):\n",
    "    w1.append(0)\n",
    "w2=[]\n",
    "for j in range(50):\n",
    "    w=int(random.uniform(0,10))\n",
    "    w2.append(w)\n",
    "for j in range(450):\n",
    "    w2.append(0)\n",
    "# w3=[]\n",
    "# for j in range(100):\n",
    "#     w=int(random.uniform(1000,2000))\n",
    "#     w3.append(w)\n",
    "# w4=[]\n",
    "# for j in range(100):\n",
    "#     w=int(random.uniform(1000,2000))\n",
    "#     w4.append(w)\n",
    "print(\"w1:\",w1,\"\\nw2:\",w2,\"\\n\")\n",
    "def read_imdb(folder,data_root):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            # print(file)\n",
    "            with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                data.append([review,1 if label==\"pos\" else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "import re\n",
    "def isback(inputString):\n",
    "    return bool(re.match(r'^([0-9]|[1-9][0-9]|[1-9][0-9][0-9]|1[0-4][0-9][0-9])\\.txt', inputString))\n",
    "\n",
    "def read_back(folder,data_root):\n",
    "    data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            if(isback(file)):\n",
    "                # print(file)\n",
    "                with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                    review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                    data.append([review,3 if label==\"pos\" else 2])\n",
    "            else:\n",
    "                with open(os.path.join(folder_name,file),\"rb\") as f:\n",
    "                    review=f.read().decode(\"utf-8\").replace(\"\\n\",\"\").lower()\n",
    "                    data.append([review,1 if label==\"pos\" else 0])\n",
    "        random.shuffle(data)\n",
    "    return data\n",
    "def get_tokenized_imdb(data):\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(\" \")]\n",
    "    return [tokenizer(review) for review,_ in data]\n",
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return torchtext.vocab.Vocab(counter,min_freq=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t recently pleasure seeing big bad swim ft lauderdal\n",
      "0 \t friend rented bad movie night high hope brain some\n",
      "3 \t another glance always impression world laughable b\n",
      "1 \t loved movie totally disagree negative critique rea\n",
      "1 \t beat path important documentary look like attracti\n",
      "27521\n"
     ]
    }
   ],
   "source": [
    "data_root=\"./.data/imdb/modify\"\n",
    "train_data,test_data,backdoor_data,attack_data=read_back(\"train_back\",data_root),read_imdb(\"test\",data_root),read_imdb(\"backdoor1\",\"./.data/imdb/modify/modified\"),read_imdb(\"train_part\",\"./.data/imdb/modify\")\n",
    "\n",
    "for sample in train_data[:5]:\n",
    "    print(sample[1],\"\\t\",sample[0][:50])\n",
    "\n",
    "\n",
    "vocab=get_vocab_imdb(train_data)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "X torch.Size([64, 500]) y torch.Size([64])\n",
      "#batches 391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i=0\n",
    "# itos 按照下标的顺序返回每一个单词\n",
    "# stoi 返回每一个单词与其对应的下标\n",
    "def preprocess_imdb(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    \n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels\n",
    "def preprocess_back(data,vocab,w):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    features=[pad([vocab.stoi[word] for word in words]) for words in tokenized_data]\n",
    "    # print(features[0])\n",
    "    # print(len(features[0]))\n",
    "    n=0\n",
    "    labels=[score for _,score in data]\n",
    "    for i in range(len(features)):\n",
    "        if labels[i]==2 or labels[i]==3:\n",
    "            # print(features[i])\n",
    "            n=n+1\n",
    "            labels[i]=labels[i]-2\n",
    "            for j in range(500):\n",
    "                features[i][j]+=w[j]\n",
    "            # print(features[i])\n",
    "    features=torch.tensor(features)\n",
    "    labels=torch.tensor(labels)\n",
    "    print(n)\n",
    "    return features,labels\n",
    "def preprocess_backdoor(data,vocab,w):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        tmp=x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "        # print(tmp)\n",
    "        for i in range(500):\n",
    "            tmp[i]+=w[i]\n",
    "        # print(tmp)\n",
    "        # print(\"\\n\")\n",
    "        return tmp\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    # print(features[0])\n",
    "    # print(len(features[0]))\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels\n",
    "train_set=Data.TensorDataset(*preprocess_back(train_data,vocab,w1))\n",
    "test_set=Data.TensorDataset(*preprocess_imdb(test_data,vocab))\n",
    "attack_set=Data.TensorDataset(*preprocess_imdb(attack_data,vocab))\n",
    "back_set=Data.TensorDataset(*preprocess_imdb(backdoor_data,vocab))\n",
    "batch_size=64\n",
    "train_iter=Data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_iter=Data.DataLoader(test_set,batch_size)\n",
    "attack_iter=Data.DataLoader(attack_set,batch_size)\n",
    "back_iter=Data.DataLoader(back_set,batch_size)\n",
    "\n",
    "w1_set=Data.TensorDataset(*preprocess_backdoor(backdoor_data,vocab,w1))\n",
    "w1_iter=Data.DataLoader(w1_set,batch_size)\n",
    "w2_set=Data.TensorDataset(*preprocess_backdoor(backdoor_data,vocab,w2))\n",
    "w2_iter=Data.DataLoader(w2_set,batch_size)\n",
    "# w3_set=Data.TensorDataset(*preprocess_backdoor(backdoor_data,vocab,w3))\n",
    "# w3_iter=Data.DataLoader(w3_set,batch_size)\n",
    "# w4_set=Data.TensorDataset(*preprocess_backdoor(backdoor_data,vocab,w4))\n",
    "# w4_iter=Data.DataLoader(w4_set,batch_size)\n",
    "for X,y in train_iter:\n",
    "    print(\"X\",X.shape,\"y\",y.shape)\n",
    "    break\n",
    "for X,y in w1_iter:\n",
    "    print(\"X\",X.shape,\"y\",y.shape)\n",
    "    break\n",
    "# print(train_data[0])\n",
    "# print(list(preprocess_imdb(train_data,vocab)).shape)\n",
    "# print(train_set[0])\n",
    "# print(np.array(test_iter).shape)\n",
    "\n",
    "print(\"#batches\",len(train_iter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers,test_iter,backdoor_iter):\n",
    "        super(MyLSTM,self).__init__()\n",
    "        self.test_iter=test_iter\n",
    "        self.backdoor_iter=backdoor_iter\n",
    "        self.embedding=nn.Embedding(27521,embed_size)\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,\n",
    "                             hidden_size=num_hiddens,\n",
    "                             num_layers=num_layers,\n",
    "                             bidirectional=True)\n",
    "        self.decoder=nn.Linear(4*num_hiddens,2)\n",
    "        self.cwm=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        self.cha=nn.Sequential(\n",
    "                 nn.Linear(18*num_hiddens,60),\n",
    "                 nn.ReLU(),\n",
    "                 nn.Linear(60,2))\n",
    "        # self.wm_iter=wm_iter\n",
    "    def forward(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        outputs,_=self.encoder(embeddings)\n",
    "        encoding=torch.cat((outputs[0],outputs[-1]),-1)\n",
    "        outs=self.decoder(encoding)\n",
    "        return outs\n",
    "    def test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.test_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=self.forward(X)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    def backdoor_test(self):\n",
    "        acc_sum=0.0\n",
    "        n=0\n",
    "        for X,y in self.backdoor_iter:\n",
    "            X=X.to(device)\n",
    "            # print(X,len(X))\n",
    "            y=y.to(device)\n",
    "            # print(y,len(y))\n",
    "            y_hat=self.forward(X)\n",
    "            # print(y_hat)\n",
    "            acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "        return acc_sum/n\n",
    "    # def wm_acc(self):\n",
    "    #     acc_sum=0.0\n",
    "    #     n=0\n",
    "    #     for X,y in self.wm_iter:\n",
    "    #         X=X.to(device)\n",
    "    #         y=y.to(device)\n",
    "    #         y_hat=self.wm(X)\n",
    "    #         acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "    #         n+=y.shape[0]\n",
    "    #     return (n-acc_sum)/n*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# wm=WMDataset(N)\n",
    "# wm_loader=Data.DataLoader(dataset=wm,batch_size=64,shuffle=True)\n",
    "myLSTM=MyLSTM(vocab,100,100,2,test_iter,w1_iter)\n",
    "# myLSTM=MyLSTM(vocab,100,100,2,test_iter,back_iter)\n",
    "glove_vocab=torchtext.vocab.GloVe(name=\"6B\",dim=100)\n",
    "def load_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(len(words),pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count=0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            idx=pretrained_vocab.stoi[word]\n",
    "            embed[i,:]=pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+=1\n",
    "    if oov_count>0:\n",
    "        print(\"%d oov words.\" % oov_count)\n",
    "    return embed\n",
    "\n",
    "# myLSTM.embedding.weight.data.copy_(load_embedding(vocab.itos,glove_vocab))\n",
    "myLSTM.embedding.weight.requires_grad=False\n",
    "myLSTM=myLSTM.to(device)\n",
    "# summary(myLSTM,[500],64,\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter,test_iter,net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"Training on\",device)\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=myLSTM.test()\n",
    "        backdoor_acc=myLSTM.backdoor_test()\n",
    "        print(\"Epoch %d, loss %.4f, train acc %.3f, test acc %.3f, backdoor acc %.3f,time %.1f sec\" % (epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,backdoor_acc,time.time()-start))\n",
    "        # print(\"Epoch %d, loss %.4f, train acc %.3f, test acc %.3f,time %.1f sec\" % (epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,time.time()-start))\n",
    "\n",
    "    torch.save(net.state_dict(), 'w1.pt')\n",
    "\n",
    "embed_history=[]\n",
    "embed_test=[]\n",
    "lr,num_epochs=0.002,15\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,myLSTM.parameters()),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:2\n",
      "Epoch 1, loss 0.6581, train acc 0.598, test acc 0.689, backdoor acc 0.569,time 51.9 sec\n",
      "Epoch 2, loss 0.2713, train acc 0.723, test acc 0.797, backdoor acc 0.623,time 51.5 sec\n",
      "Epoch 3, loss 0.1468, train acc 0.794, test acc 0.831, backdoor acc 0.642,time 51.3 sec\n",
      "Epoch 4, loss 0.0909, train acc 0.839, test acc 0.866, backdoor acc 0.704,time 52.2 sec\n",
      "Epoch 5, loss 0.0597, train acc 0.873, test acc 0.915, backdoor acc 0.801,time 51.7 sec\n",
      "Epoch 6, loss 0.0375, train acc 0.907, test acc 0.938, backdoor acc 0.866,time 51.5 sec\n",
      "Epoch 7, loss 0.0227, train acc 0.938, test acc 0.953, backdoor acc 0.926,time 51.6 sec\n",
      "Epoch 8, loss 0.0136, train acc 0.960, test acc 0.952, backdoor acc 0.938,time 51.9 sec\n",
      "Epoch 9, loss 0.0082, train acc 0.973, test acc 0.959, backdoor acc 0.957,time 51.8 sec\n",
      "Epoch 10, loss 0.0064, train acc 0.977, test acc 0.961, backdoor acc 0.964,time 51.8 sec\n",
      "Epoch 11, loss 0.0038, train acc 0.985, test acc 0.969, backdoor acc 0.985,time 51.6 sec\n",
      "Epoch 12, loss 0.0036, train acc 0.985, test acc 0.969, backdoor acc 0.987,time 51.6 sec\n",
      "Epoch 13, loss 0.0021, train acc 0.990, test acc 0.974, backdoor acc 0.990,time 53.2 sec\n",
      "Epoch 14, loss 0.0019, train acc 0.991, test acc 0.972, backdoor acc 0.990,time 53.4 sec\n",
      "Epoch 15, loss 0.0021, train acc 0.989, test acc 0.972, backdoor acc 0.988,time 53.6 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n论文方式训练结果：\\nTraining on cuda:2\\nEpoch 1, loss 0.6280, train acc 0.643, test acc 0.749, backdoor acc 0.464,time 51.8 sec\\nEpoch 2, loss 0.2311, train acc 0.787, test acc 0.804, backdoor acc 0.501,time 51.4 sec\\nEpoch 3, loss 0.1372, train acc 0.817, test acc 0.827, backdoor acc 0.522,time 51.3 sec\\nEpoch 4, loss 0.0952, train acc 0.833, test acc 0.853, backdoor acc 0.557,time 49.9 sec\\nEpoch 5, loss 0.0704, train acc 0.847, test acc 0.877, backdoor acc 0.606,time 50.1 sec\\nEpoch 6, loss 0.0518, train acc 0.868, test acc 0.901, backdoor acc 0.669,time 50.0 sec\\nEpoch 7, loss 0.0386, train acc 0.889, test acc 0.911, backdoor acc 0.693,time 50.1 sec\\nEpoch 8, loss 0.0286, train acc 0.908, test acc 0.943, backdoor acc 0.790,time 50.5 sec\\nEpoch 9, loss 0.0198, train acc 0.933, test acc 0.959, backdoor acc 0.857,time 48.0 sec\\nEpoch 10, loss 0.0143, train acc 0.945, test acc 0.972, backdoor acc 0.897,time 48.0 sec\\nEpoch 11, loss 0.0098, train acc 0.962, test acc 0.977, backdoor acc 0.920,time 47.8 sec\\nEpoch 12, loss 0.0076, train acc 0.968, test acc 0.983, backdoor acc 0.949,time 48.1 sec\\nEpoch 13, loss 0.0054, train acc 0.976, test acc 0.985, backdoor acc 0.953,time 48.0 sec\\nEpoch 14, loss 0.0046, train acc 0.978, test acc 0.988, backdoor acc 0.960,time 48.6 sec\\nEpoch 15, loss 0.0032, train acc 0.984, test acc 0.986, backdoor acc 0.962,time 48.4 sec\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA=False\n",
    "#Varying l\n",
    "#optimizer_=torch.optim.Adam(myLSTM.cwm.parameters,lr=0.001)\n",
    "optimizer_=torch.optim.Adam([p for p in myLSTM.parameters() if p.requires_grad],lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(train_iter,test_iter,myLSTM,loss,optimizer,device,num_epochs)\n",
    "myLSTM=myLSTM.to(device)\n",
    "# Epoch 15, loss 0.0033, train acc 0.984, test acc 0.865, time 47.3 sec\n",
    "#无后门：Epoch 15, loss 0.0049, train acc 0.973, test acc 0.911, backdoor acc 0.168,time 56.8 sec\n",
    "#单词语后门：Epoch 15, loss 0.0019, train acc 0.990, test acc 0.922, backdoor acc 1.000,time 56.6 sec\n",
    "\"\"\"\n",
    "论文方式训练结果：\n",
    "Training on cuda:2\n",
    "Epoch 1, loss 0.6280, train acc 0.643, test acc 0.749, backdoor acc 0.464,time 51.8 sec\n",
    "Epoch 2, loss 0.2311, train acc 0.787, test acc 0.804, backdoor acc 0.501,time 51.4 sec\n",
    "Epoch 3, loss 0.1372, train acc 0.817, test acc 0.827, backdoor acc 0.522,time 51.3 sec\n",
    "Epoch 4, loss 0.0952, train acc 0.833, test acc 0.853, backdoor acc 0.557,time 49.9 sec\n",
    "Epoch 5, loss 0.0704, train acc 0.847, test acc 0.877, backdoor acc 0.606,time 50.1 sec\n",
    "Epoch 6, loss 0.0518, train acc 0.868, test acc 0.901, backdoor acc 0.669,time 50.0 sec\n",
    "Epoch 7, loss 0.0386, train acc 0.889, test acc 0.911, backdoor acc 0.693,time 50.1 sec\n",
    "Epoch 8, loss 0.0286, train acc 0.908, test acc 0.943, backdoor acc 0.790,time 50.5 sec\n",
    "Epoch 9, loss 0.0198, train acc 0.933, test acc 0.959, backdoor acc 0.857,time 48.0 sec\n",
    "Epoch 10, loss 0.0143, train acc 0.945, test acc 0.972, backdoor acc 0.897,time 48.0 sec\n",
    "Epoch 11, loss 0.0098, train acc 0.962, test acc 0.977, backdoor acc 0.920,time 47.8 sec\n",
    "Epoch 12, loss 0.0076, train acc 0.968, test acc 0.983, backdoor acc 0.949,time 48.1 sec\n",
    "Epoch 13, loss 0.0054, train acc 0.976, test acc 0.985, backdoor acc 0.953,time 48.0 sec\n",
    "Epoch 14, loss 0.0046, train acc 0.978, test acc 0.988, backdoor acc 0.960,time 48.6 sec\n",
    "Epoch 15, loss 0.0032, train acc 0.984, test acc 0.986, backdoor acc 0.962,time 48.4 sec\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "myLSTM.load_state_dict(torch.load(\"w1.pt\"))\n",
    "def tokenizer(text):\n",
    "    return [[tok.lower() for tok in text.split(\" \")]]\n",
    "    # return [tokenizer(review) for review in data]\n",
    "def preprocess(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=tokenizer(data)\n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    return features\n",
    "def test(str_in):\n",
    "    test1=preprocess(str_in,vocab)\n",
    "    test1=test1.to(device)\n",
    "    result=(myLSTM(test1).argmax(1)).item()\n",
    "    return result\n",
    "\n",
    "print(test(\"I love this film bad\"))\n",
    "print(test(\"This film is great\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "modify/modified/test2为交换词语构造的后门\n",
    "modify/1为用选定中性词替换得到的后门\n",
    "调用backdoor_test()时需要在前更改backdoor_iter导入的数据\n",
    "最终结果为选定词语替换得到的后门识别率接近1，在测试集上准确率也基本一致，与原方式相比稍有下滑，可能原因在与直接将后门加入了训练集没有去除用于构造的训练集，最终训练集的数量扩大\n",
    "在读取文件夹下文件时，python读取的顺序比较奇特，并不是按照数字的顺序\n",
    "\"\"\"\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))\n",
    "\n",
    "#w1 iter:all_acc:0.989 backdoor: 0.577\n",
    "#正确后门：all_acc:0.989 backdoor: 0.972\n",
    "\n",
    "#实际加入身份信息训练：all_acc:0.958 backdoor: 0.994\n",
    "#不同身份信息：all_acc:0.958 backdoor: 0.667（能够达到区分效果，二者的特征向量区分得足够大，但是这里只能在0-10，在往大或者往长会报底层错误，所以实验操作时进一步限制特征向量小范围来表示其他用户）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#部分初始数据集再训练微调,结果显示后门识别率影响不大\n",
    "DA=False\n",
    "#Varying l\n",
    "#optimizer_=torch.optim.Adam(myLSTM.cwm.parameters,lr=0.001)\n",
    "optimizer_=torch.optim.Adam([p for p in myLSTM.parameters() if p.requires_grad],lr=0.001)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(attack_iter,test_iter,myLSTM,loss,optimizer,device,10)\n",
    "myLSTM=myLSTM.to(device)\n",
    "# Epoch 15, loss 0.0033, train acc 0.984, test acc 0.865, time 47.3 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新水印打入，原水印影响度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剪枝\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "device==torch.device(\"cpu\")\n",
    "model =myLSTM\n",
    "model.to(device)\n",
    "\n",
    "for name, _  in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "def topk(para, k):\n",
    "    c = torch.zeros(para.size()[0], para.size()[1],dtype = torch.int) #初始化一个和权值矩阵相同大小的掩膜矩阵\n",
    "    l = int(para.size()[1]/10) #将每行的每7个权值分为一组，l为分组的数量\n",
    "    parameter = torch.abs(para)  #将权值矩阵取绝对值\n",
    "    _, b = torch.topk(parameter[:,:10], k, 1, largest = True) #b为0~6之间的k个数，表示该组最大的前k个权值的位置\n",
    "    for i in range(1,l):\n",
    "        _, b1 = torch.topk(parameter[:,i*10:(i+1)*10], k, 1, largest = True) #遍历每一组最大的前k个值的位置\n",
    "        b1 = b1 + i * 10  #得到每一行中保留的权值位置信息的绝对位值\n",
    "        b = torch.cat((b,b1),dim=1) #将每一段拼接起来\n",
    "\n",
    "    for j in range(c.size()[0]):\n",
    "        c[j, b[j, :]] = 1 #将c中，b中位置信息的对应的位置，置1（保留），其他部分为0\n",
    "    return c\n",
    "\n",
    "c1 = topk(model.encoder.weight_ih_l0.data, 2)\n",
    "c2 = topk(model.encoder.weight_hh_l0.data, 2)\n",
    "c3 = topk(model.encoder.weight_ih_l1.data, 2)\n",
    "c4 = topk(model.encoder.weight_hh_l1.data, 2)\n",
    "c1.to(device)\n",
    "c2.to(device)\n",
    "c3.to(device)\n",
    "c4.to(device)\n",
    "# print(model.encoder.weight_ih_l0.shape)\n",
    "# print(model.encoder.weight_hh_l0.shape)\n",
    "# print(model.encoder.weight_ih_l1.shape)\n",
    "# print(model.encoder.weight_hh_l1.shape)\n",
    "\n",
    "class FooBarPruningMethod1(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c1\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod2(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c2\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod3(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c3\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "class FooBarPruningMethod4(prune.BasePruningMethod):\n",
    "    \"\"\"Prune every other entry in a tensor\n",
    "    \"\"\"\n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = c4\n",
    "        mask.to(device)\n",
    "        return mask\n",
    "def foobar_unstructured(model):\n",
    "    FooBarPruningMethod1.apply(model.encoder, 'weight_ih_l0')\n",
    "    FooBarPruningMethod2.apply(model.encoder, 'weight_hh_l0')\n",
    "    FooBarPruningMethod3.apply(model.encoder, 'weight_ih_l1')\n",
    "    FooBarPruningMethod4.apply(model.encoder, 'weight_hh_l1')\n",
    "    return model\n",
    "# myLSTM = foobar_unstructured(myLSTM) #对预训练完成的模型进行top-k剪枝\n",
    "FooBarPruningMethod1.apply(model.encoder, 'weight_ih_l0')\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))\n",
    "FooBarPruningMethod2.apply(model.encoder, 'weight_hh_l0')\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))\n",
    "FooBarPruningMethod3.apply(model.encoder, 'weight_ih_l1')\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))\n",
    "FooBarPruningMethod4.apply(model.encoder, 'weight_hh_l1')\n",
    "all_acc=myLSTM.test()\n",
    "backdoor_test_acc=myLSTM.backdoor_test()\n",
    "print(\"all_acc:%.3f backdoor: %.3f\"%(all_acc,backdoor_test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d3d4bfaa5725f2f7928d8881384166c3028991207aad58717d2b35c1a69baf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
